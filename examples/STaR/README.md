# Code implementation of "STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning"

Blog post <https://paperwithoutcode.com/star-self-taught-reasoner-bootstrapping-reasoning-with-reasoning/#code>

Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah D. Goodman
The official github repo is https://github.com/ezelikman/STaR

The 2022 paper “STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning” presents a groundbreaking method to enhance reasoning in language models through iterative rationale generation and refinement. This Self-Taught Reasoner (STaR) approach enables model self-improvement by creating and fine-tuning on rationales, or step-by-step reasoning explanations, which lead to correct answers. By integrating rationalization, where the model generates rationales based on provided correct answers, STaR mitigates the need for extensive human-annotated datasets. This method demonstrates significant performance gains across symbolic reasoning tasks like arithmetic and natural language reasoning tasks such as commonsense question answering, thus positioning it as a superior alternative to traditional few-shot learning and direct fine-tuning approaches. Emphasized by human evaluators, the STaR-generated rationales frequently surpass even human-generated reasoning in coherence and quality. The iterative refinement process, advocating for continuous self-enhancement, marks a novel stride in machine learning, aligning with the ambitions of advanced AI systems like OpenAI’s rumored Strawberry AGI. Future research could explore STaR’s scalability to varied domains, mitigation of biases, and further enhancement of rationale faithfulness, making this paper a valuable read for researchers and graduate students aiming to advance AI reasoning capabilities.