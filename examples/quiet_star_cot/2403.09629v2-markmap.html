<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.1-alpha.4/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.17.1-alpha.4/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.1-alpha.4/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:q,mm:v}=window,j=new q.Toolbar;j.attach(v);const we=j.render();we.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(we)})})()</script><script>((f,d,h,u)=>{const g=f();window.mm=g.Markmap.create("svg#mindmap",(d||g.deriveOptions)(u),h)})(()=>window.markmap,null,{"content":"Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking","children":[{"content":"Research Question/Objective","children":[{"content":"Generalization of STaR","children":[{"content":"Extend STaR method beyond QA datasets to unstructured text data.","children":[],"payload":{"lines":"5,6"}},{"content":"Improve LM predictions by generating rationales at each token.","children":[],"payload":{"lines":"6,8"}}],"payload":{"lines":"4,5"}}],"payload":{"lines":"3,4"}},{"content":"Methodology","children":[{"content":"Quiet-STaR Overview","children":[{"content":"Parallel Rationale Generation","children":[{"content":"Tokenwise parallel sampling algorithm to generate rationales for each token.","children":[],"payload":{"lines":"11,12"}},{"content":"Custom attention mask for efficiency.","children":[],"payload":{"lines":"12,13"}}],"payload":{"lines":"10,11"}},{"content":"Mixing (Residual) Heads","children":[{"content":"Shallow multi-layer perceptron to combine predictions with and without thoughts.","children":[],"payload":{"lines":"14,15"}}],"payload":{"lines":"13,14"}},{"content":"Optimizing Rationale Generation","children":[{"content":"Optimizing Start-of-Thought and End-of-Thought Tokens","children":[{"content":"Use REINFORCE to optimize rationale generation.","children":[],"payload":{"lines":"17,18"}}],"payload":{"lines":"16,17"}},{"content":"Non-myopic Scoring and Teacher-forcing","children":[{"content":"Consider multiple future tokens for more holistic reasoning.","children":[],"payload":{"lines":"19,21"}}],"payload":{"lines":"18,19"}}],"payload":{"lines":"15,16"}}],"payload":{"lines":"9,10"}}],"payload":{"lines":"8,9"}},{"content":"Key Findings/Contributions","children":[{"content":"Performance Improvements","children":[{"content":"Zero-shot improvements on GSM8K (5.9% to 10.9%) and CommonsenseQA (36.3% to 47.2%).","children":[],"payload":{"lines":"23,24"}}],"payload":{"lines":"22,23"}},{"content":"Distribution of Improvements","children":[{"content":"Disproportionately improves prediction accuracy for difficult-to-predict tokens.","children":[],"payload":{"lines":"25,27"}}],"payload":{"lines":"24,25"}}],"payload":{"lines":"21,22"}},{"content":"Theoretical Framework","children":[{"content":"REINFORCE Algorithm","children":[{"content":"Reward rationales leading to better future token predictions.","children":[],"payload":{"lines":"29,30"}}],"payload":{"lines":"28,29"}},{"content":"Non-myopic Loss Function","children":[{"content":"Encourages more comprehensive reasoning by considering multiple tokens ahead.","children":[],"payload":{"lines":"31,33"}}],"payload":{"lines":"30,31"}}],"payload":{"lines":"27,28"}},{"content":"Results and Discussion","children":[{"content":"Downstream Performance","children":[{"content":"Significant zero-shot reasoning improvements without task-specific fine-tuning.","children":[],"payload":{"lines":"35,36"}}],"payload":{"lines":"34,35"}},{"content":"Comparison with Chain-of-Thought","children":[{"content":"Quiet-STaR enhances reasoning when combined with chain-of-thought prompting.","children":[],"payload":{"lines":"37,38"}}],"payload":{"lines":"36,37"}},{"content":"Examples","children":[{"content":"Provided examples demonstrating model performance on reasoning tasks.","children":[],"payload":{"lines":"39,41"}}],"payload":{"lines":"38,39"}}],"payload":{"lines":"33,34"}},{"content":"Implications","children":[{"content":"Scalability and Generalizability","children":[{"content":"Quiet-STaR can be applied to a wide range of reasoning tasks using diverse unstructured text.","children":[],"payload":{"lines":"43,44"}}],"payload":{"lines":"42,43"}},{"content":"Complementary Techniques","children":[{"content":"Shows potential when combined with other reasoning methods like chain-of-thought.","children":[],"payload":{"lines":"45,47"}}],"payload":{"lines":"44,45"}}],"payload":{"lines":"41,42"}},{"content":"Limitations","children":[{"content":"Technical Complexity and Overheads","children":[{"content":"Intricate algorithms may pose challenges for those not familiar with advanced NLP and RL techniques.","children":[],"payload":{"lines":"49,50"}},{"content":"Significant computational overhead due to additional rationale generation.","children":[],"payload":{"lines":"50,52"}}],"payload":{"lines":"48,49"}}],"payload":{"lines":"47,48"}},{"content":"Future Research Directions","children":[{"content":"Dynamic Rationale Generation","children":[{"content":"Explore dynamic allocation of compute to generate rationales only when needed.","children":[],"payload":{"lines":"54,55"}}],"payload":{"lines":"53,54"}},{"content":"Broader Evaluations","children":[{"content":"Test Quiet-STaR on a wider range of reasoning tasks to validate generalizability.","children":[],"payload":{"lines":"56,57"}}],"payload":{"lines":"55,56"}},{"content":"Human-in-the-Loop Training","children":[{"content":"Introduce human feedback to guide and validate rationale generation.","children":[],"payload":{"lines":"58,60"}}],"payload":{"lines":"57,58"}}],"payload":{"lines":"52,53"}},{"content":"Ethics Statement","children":[{"content":"Faithfulness of Rationales","children":[{"content":"Generated rationales may not accurately represent the model's internal processing.","children":[],"payload":{"lines":"62,63"}}],"payload":{"lines":"61,62"}},{"content":"Harmful or Biased Reasoning","children":[{"content":"No safeguards against harmful or biased reasoning patterns in generated rationales.","children":[],"payload":{"lines":"64,66"}}],"payload":{"lines":"63,64"}}],"payload":{"lines":"60,61"}},{"content":"Acknowledgements","children":[],"payload":{"lines":"66,67"}},{"content":"References","children":[],"payload":{"lines":"68,69"}}],"payload":{"lines":"1,2"}},{"colorFreezeLevel":5,"initialExpandLevel":-1,"maxWidth":300})</script>
</body>
</html>
